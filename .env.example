# ---- LLM ----
LLM_MODE=open_source
LLM_PROVIDER=ollama
MODEL_NAME=qwen2.5:14b-instruct
AI_BASE_URL=https://your-openai-compatible-endpoint
# 示例：闭源 Qwen (DashScope OpenAI 兼容) 用 https://dashscope.aliyuncs.com/compatible-mode/v1
# 示例：Ollama 本地模型用 http://127.0.0.1:11434/v1
API_KEY=your_api_key_here

# ---- Embeddings ----
EMBEDDING_MODE=open_source
EMBEDDING_PROVIDER=huggingface
EMBEDDING_MODEL_NAME=BAAI/bge-m3
EMBEDDING_DEVICE=cpu
EMBEDDING_BASE_URL=
EMBEDDING_API_KEY=

# ---- RAG ----
VECTOR_STORE_DIR=data/vector_store
CHUNK_STRATEGY=recursive
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHROMA_HOST=vector-db
CHROMA_HTTP_PORT=8000
CHROMA_SSL=false

# ---- Web search ----
TAVILY_API_KEY=your_tavily_api_key

# ---- Observability ----
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=devmate
LANGSMITH_ENDPOINT=

# ---- MCP (client/server) ----
MCP_TRANSPORT=stdio
MCP_HTTP_URL=http://127.0.0.1:8010/mcp
MCP_SSE_URL=http://127.0.0.1:8000/sse
MCP_HOST=127.0.0.1
MCP_PORT=8010

# ---- Logging ----
LOG_LEVEL=INFO
LOG_FILE=logs/devmate.log

# ---- Chroma telemetry ----
CHROMA_TELEMETRY_ENABLED=0
POSTHOG_DISABLE=1
ANONYMIZED_TELEMETRY=false
